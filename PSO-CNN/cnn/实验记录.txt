
训练次数，用同样的样本集改正cnnff函数之后。我训练的时候：
600 的时候,error 95.8084%
修改个体极值初始值都为5后，300次，error为90.8184%
进行自适应度的修改300次，error为93.6128%
选取（0.6,1.7,1.7）时，error为88.4232% 
第二十六次实验 pso传给bp，然后让bp一直跑 error 95.8084%
没有PSO，直接使用BP（批量梯度）， error 91.8164%
没有PSO，直接使用BP（随机梯度取4一组），error 4.3912%


6.7-6.13
第二十九次实验：没有用PSO，只是用SGD（使用的原来的cnnsetup初始化），plot的是net.rL量，用来对比彭博的实验结果图          4.7904% error
第三十次实验  ：PSO和SGD切换，result表示每一次的前向的均方误差net.L（适应度）                                         94.012% error
    尝试方向：结果不理想，试试测试不用PSO，只跑SGD（使用cnnassign函数），即测试cnnassign函数
第三十一次实验：测试cnnassign函数，（除去PSO，使用cnnasssign来跑SGD）                                                87.0259% error
第三十二次实验：测试修改后的cnnassign函数，其他同31次实验，结果依旧不理想                                             90.8184% error

6.14-6.20
第三十三次实验：注释掉cnnassign函数，只用cnnsetup函数，因为net所带的权值即最后一个粒子初始化时的值(检测cnnsetup函数)    4.5908% error
第三十四次实验：上一次结果很理想，说明cnnassign函数有问题，要继续检查(发现cnnassign的初始pso_start放错位置)，改后       4.3912% error
               再次测试结果理想，至此cnnsetup和cnnassign函数及cnnapplygrads函数都没有问题
第三十五次实验：PSO和SGD切换，设置切换条件10代差0.05,结果不理想。                                                     91.8164% error
第三十六次实验：PSO传给SGD，然后让SGD一直跑，300次迭代，结果不算理想                                                  15.1697% error
第三十七次实验：当前适应度与10次之前的和20次之前的适应度都要大于0.05呢，结果不理想                                     90.4192% error

7.1-7.7
第三十八次实验：单独让PSO跑一下（因为改过cnassign函数），效果会不会好些，结果依旧和之前单独PSO一样                      92.016% error
第三十九次实验(关键)：对SGD的result做改变，如result(end+1)=0.99*result(end) + 0.01*net.fitness(num)，虽然结果较理想   7.1856% error
               但观察实验过程后发现，从25次后一直进行随机梯度SGD，也就是说之后一直没有满足切换PSO的条件，等于刚开始
               调用了PSO，后再一直调用SGD。
第四十次实验：  设置切换PSO代差10代为0.01，20代为0.05，结果较理想，但是过程如同第三十九次实验一样，先PSO后一直SGD，
               没有满足切换PSO                                                                                     3.7924% error

7.8-7.15
第四十一次实验: 本次实验共300次迭代，其中PSO占153次，SGD占147次。         训练集 10.0671% error                  测试集 9.1816% error

第四十二次实验：软切换，i<15||result_PSO-result(end-5)>0.005 %若之前PSO的误差值减去最后的误差,后面的迭代只要满足  训练集 11.745% error 
               这个条件即可切换到pso，而不用管SGD进行了多少次。但是过程显示后面PSO切换后只有一次，切换条件设置不合理  测试集  9.1816% error
               另彭博的原版程序训练集 5.0336% error  测试集 3.992% error

第四十三次实验：条件设置不合理，导致了四十二次实验的情况。因为后面切换到PSO，PSO的误差会比SGD小，不满足再进行PSO的条件
               所以设置成if(i<15||abs(result_PSO-result(end-10))>0.005)，绝对值避免了这个问题，同时代数扩大到10代。    92.016% error

7.18-7.25
对四十一次实验和四十二次实验训练集进行测试，及彭博的程序进行训练集测试。 
对比彭博的程序300次迭代和600次迭代进行对比，300次时  训练集 5.0336% error  测试集 4.3912% error
                                         600次时  训练集 8.2215% error  测试集 4.1912% error

7.26-8.2
mnist数据集 刚开始的我自己的数据集错误率为89.68% error  后来彭博的数据集没有二值化时（50次迭代）的错误率为1.45% error

8.3-8.9
用自己的mnist数据集没有二值化的时候（50次迭代）测试错误率1.2% error，证实了不是数据集有问题，而是二值化导致CNN训练不够完全，特征提取不够  1.2% errpr

8.17-8.28
第四十四次实验：重新实现第四十一次实验的过程，将SGD中的net.fitnessgbest更新语句修改为 net.fitnessgbest=result(end);
               这样就消除了结果图中跳崖情况。

10.1-10.11
第四十五次实验：实现clpso，结果很不理想                                                                              91.8164% error
第四十六次实验：对比发现，速度异常小，达到e-198，后来调参，改变了w权重的公式（clpso原文流程图的w应该有问题）              97.006% error
                                                          设置m=3                                                  93.6128% error

查看代码结果：
改动
   1.m=7，过大，对于我们的300次循环太大，人家是30000次迭代。或者我们把迭代次数设大一些。取了m=3
   2.查看中间结果，最后速度异常小，速度参考《粒子群优化算法中惯性权重的研究进展》的文献（6），设置w1=0.6
   3.因为原先第十八次实验使用gbest来引导更新,所以设置gbest较高为5，设置太低时，不能更新，pbest同样。

10.12-10.17
第四十七次实验：迭代次数设为20000，clpso有提升。（但是当时还没发现边界问题）                                       75.2495% error
                尝试归一化，后发现已经归一化，遂弃。
第四十八次实验：因之前SGD和pso混合，粒子一直未异常超出，且边界值不知设多少，故边界注释掉了，后发现粒子超出边界故而又设置，
                参看第40次实验，此为最好结果，粒子基本都不超过[-1.5,1.5],参看粒子群综述，速度一般设置成解空间的10%-20%   92.02%

10.18-10.25
第四十九次实验：调换了速度和适应度更新位置，以免刚开始pbestpar与par相同，速度过小。100次迭代                            95.8084% error
第五十次实验: 随机初始化了pbestfitness，减小了refreshing map m=3                                                     93.6128% error

ps：第五十次实验后吧每次迭代的result保存到net中，即cnn中
第五十一实验：改掉选择过程的判断条件（选取更新粒子的那个过程）                    3000次迭代                           83.6327% error
第五十二次实验：设置rand<Pc(num),以此来增加从其他粒子更新的几率 (已经改回来了)      300次迭代                          92% error
第五十三次实验：标准pso对gbsetpar做梯度，然后对所有粒子更新使用                   2000次迭代                           91.8164% error
               
10.26-11.1
第五十三次实验：后发现代码有问题需要修改(update放到sgd里面)                      2000次迭代                修改后     3.1936% error
第五十次四实验：把update函数放在sgd外面                                         600次迭代                            5.59%  error
第五十五次实验：对clpso使用了300个粒子                                         300次迭代                             88.98% error                
第五十六次实验：把update放到sgd里面                                             600次迭代                           3.3932% error
 
11.2-11.8
第五十七次试验：用mnist数据集                                                  600次迭代（一星期）                   1.58%error                